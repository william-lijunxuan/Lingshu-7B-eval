### 机器翻译/生成类

* **BLEU-1/2/3/4**
  基于 n-gram 精确匹配的分数；分别统计 1-gram、2-gram、3-gram、4-gram 的匹配情况，并带有**brevity penalty**（长度惩罚）。
  取值：0–1（或 0–100%）。数值越大越好。
  要点：偏向**“表面词串一致”**；句式变化、同义替换多时分数会被低估。BLEU-4最常见；BLEU-1更敏感于关键词覆盖。

* **ROUGE-1 / ROUGE-2 / ROUGE-L**
  原用于摘要评测。

  * ROUGE-1：基于 1-gram 的**召回率**（常见也会给 F1）。
  * ROUGE-2：基于 2-gram 的召回率。
  * **ROUGE-L**：基于**最长公共子序列（LCS）**的重合度，能一定程度捕捉到序列级对齐。
    取值：0–1（或 0–100%）；越大越好。
    要点：更偏重**覆盖到参考要点**；与 BLEU 相比，对词序变化更鲁棒（尤其是 ROUGE-L）。

* **METEOR**
  基于**词对齐**，综合精确率与召回率，并支持词形还原、同义词（WordNet）等匹配。
  取值：0–1；越大越好。
  要点：相比 BLEU/ROUGE 对同义替换更友好，往往与人工主观评分相关性更高。

### 分类/抽取/问答常用

* **precision（精确率）**
  预测为正的样本中，真正为正的比例。
  公式：TP / (TP + FP)。
  含义：预测命中的**准确性**。

* **recall（召回率）**
  实际为正的样本中，被正确找回的比例。
  公式：TP / (TP + FN)。
  含义：预测的**覆盖能力**。

* **F1**
  精确率与召回率的调和平均。
  公式：2·P·R / (P + R)。
  含义：在准确性与覆盖之间的平衡；0–1，越大越好。
  备注：可扩展为微/宏平均、多类别/多标签版本。

* **EM（Exact Match）**
  **完全匹配率**：预测答案与参考答案在字符串层面完全一致的比例（常用于抽取式阅读理解/问答）。
  取值：0–1；越大越好。
  要点：极为严格，任何字符/标点/大小写差异都可能判错；常与 F1（基于分词的重合度）一起报告。

### 选择与解读建议

* 生成任务：同时给出 **BLEU-4、ROUGE-L、METEOR** 可获得较全面视角（表面匹配 vs 语义近似）。
* 摘要任务：**ROUGE** 系列更主流，辅以 **METEOR**。
* 抽取/分类/QA：报告 **EM 与 F1**；若多标签或严重类不均衡，再补充**宏/微平均**的 P/R/F1。
* 报告数值时，建议同时给出**置信区间或多次运行方差**，并设置**“有意义提升”的阈值**（如 F1/ROUGE/METEOR 提升 ≥1–2 个点且超出随机波动）。


| 指标                  | 匹配视角              | 是否多参考 | 对同义/改写鲁棒性 | 典型任务     |
| ------------------- | ----------------- | ----- | --------- | -------- |
| BLEU-1/2/3/4        | n-gram 精确率 + 长度惩罚 | 支持    | 较弱        | 翻译、生成    |
| ROUGE-1/2           | n-gram 召回（或F1）    | 支持    | 中等        | 摘要、关键词覆盖 |
| ROUGE-L             | LCS（序列级）          | 支持    | 中等偏强      | 摘要、长句结构  |
| METEOR              | 词对齐（含词形/同义）       | 支持    | 较强        | 翻译、生成    |
| Precision/Recall/F1 | 类别/span 级         | 视实现   | 语义由标注定义   | 分类、抽取、QA |
| EM                  | 严格字符串一致           | 支持    | 很弱        | 抽取式 QA   |
